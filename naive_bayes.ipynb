{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('q3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePriors(Y, dict_Y):\n",
    "    '''\n",
    "        Calculate P(Ci) i.e. probability of class/label i\n",
    "    '''\n",
    "    \n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "    \n",
    "    dict_Y['True'] = counts[1] / len(Y)\n",
    "    dict_Y['False'] = counts[0] / len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePosterior_category(data, feature_name, dict_X, Y):\n",
    "    '''\n",
    "        Calculate Posteriors : P(feature_name = val| is spam = True) and P(feature_name = val| is spam = False)\n",
    "        for each val in values for feature_name\n",
    "    '''\n",
    "    \n",
    "    values = list(data[feature_name].unique())\n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "    \n",
    "    for val in values:\n",
    "        set_reqd = data[data[feature_name] == val]\n",
    "        \n",
    "        # For spam true\n",
    "        key = feature_name + ', %s' % val + ', spam, True'\n",
    "        dict_X[key] = len(set_reqd[set_reqd[' is spam'] == True]) / counts[1]\n",
    "        \n",
    "        # For spam false\n",
    "        key = feature_name + ', %s' % val + ', spam, False'\n",
    "        dict_X[key] = len(set_reqd[set_reqd[' is spam'] == False]) / counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, means, std_devs, feature, label):\n",
    "    '''\n",
    "        Calculates g(x, mean, std_dev) = ((sq_root(2 * pi) * (std_dev)^2)^-1) * exp(-1 * (x - mean)^2 / 2 * std_dev^2)\n",
    "    '''\n",
    "    # If prior calculation then label will be '' so key would be only feature name\n",
    "    if label != '':\n",
    "        key = feature + ',' + str(label)\n",
    "    else:\n",
    "        key = feature\n",
    "    mean = means[key]\n",
    "    std_dev = std_devs[key]\n",
    "    \n",
    "    exp_value = np.exp((-1 * np.square(x - mean)) / (2 * np.square(std_dev)))\n",
    "    \n",
    "    coefficient = np.power( (np.sqrt(2 * np.pi) * std_dev), -1 )\n",
    "    \n",
    "    return coefficient * exp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePosterior_contus(data_train, feature_name, x, label, means, std_devs):\n",
    "    '''\n",
    "        Calculate Posterior for continuous : P(feature_name = x| is spam = label)\n",
    "    '''\n",
    "    \n",
    "    return gaussian(x=x, means=means, std_devs=std_devs, feature=feature_name, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeature_Likelihood(data_train, feature_name, dict_X):\n",
    "    '''\n",
    "        Calculate P(feature_name = x) and store in a dictionary\n",
    "    '''\n",
    "    # We will use gaussian function for probability of contus features later\n",
    "    set_feature = data_train.drop([' # sentences', ' # words'], axis=1)\n",
    "    \n",
    "    for x in list(set_feature[feature_name].unique()):\n",
    "        key = feature_name + ', %s' % x\n",
    "        dict_X[key] = len(set_feature[set_feature[feature_name] == x]) / len(set_feature[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features(train_X, features, dict_X, means, std_devs):\n",
    "    '''\n",
    "        Filters features based on gini index (We need probabilities so cannot do it for continuous)\n",
    "        Gini = summation((probability for each value and class pair) ^ 2)\n",
    "    '''\n",
    "    gini = {}\n",
    "    for feature in features:\n",
    "        # For each class one value of probability\n",
    "        prob = 0\n",
    "        if type(train_X[feature][0]) != np.int64:\n",
    "            prob += np.square(dict_X['%s, True, spam, True' % feature])\n",
    "            prob += np.square(dict_X['%s, False, spam, True' % feature])\n",
    "            prob += np.square(dict_X['%s, True, spam, True' % feature])\n",
    "            prob += np.square(dict_X['%s, False, spam, True' % feature])\n",
    "            \n",
    "            gini[feature] = prob\n",
    "            \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in html',\n",
       " ' has emoji',\n",
       " ' sent to list',\n",
       " ' from .com',\n",
       " ' has sig',\n",
       " ' # sentences',\n",
       " ' # words']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train.drop(' is spam', axis=1)\n",
    "train_Y = train[' is spam']\n",
    "\n",
    "dict_Y = {}\n",
    "computePriors(Y=train_Y, dict_Y=dict_Y)\n",
    "#print(dict_Y)\n",
    "\n",
    "features = train_X.columns.values\n",
    "\n",
    "# Keys are of type 'feature, value, spam, label' or 'feature, value'\n",
    "dict_X = {}\n",
    "\n",
    "# Keys are of type 'feature, value, spam, label' or 'feature, value'\n",
    "means = {}\n",
    "std_devs = {}\n",
    "\n",
    "for feature in features:\n",
    "    # If it has int values then continous else not\n",
    "    if type(train_X[feature][0]) != np.int64:\n",
    "        computePosterior_category(data=train, feature_name=feature, dict_X=dict_X, Y=train_Y)\n",
    "        # Compute probabilities of feature values\n",
    "        computeFeature_Likelihood(data_train=train_X, feature_name=feature, dict_X=dict_X)\n",
    "    else:\n",
    "        # For each class\n",
    "        means[feature + ',' + str(True)] = np.mean(train[train[' is spam'] == True][feature])\n",
    "        means[feature + ',' + str(False)] = np.mean(train[train[' is spam'] == False][feature])\n",
    "        std_devs[feature + ',' + str(True)] = np.std(train[train[' is spam'] == True][feature])\n",
    "        std_devs[feature + ',' + str(False)] = np.std(train[train[' is spam'] == False][feature])\n",
    "        \n",
    "        # For whole set\n",
    "        means[feature] = np.mean(train_X[feature])\n",
    "        std_devs[feature] = np.std(train_X[feature])\n",
    "        \n",
    "gini = filter_features(train_X=train_X, features=features, dict_X=dict_X, means=means, std_devs=std_devs)\n",
    "\n",
    "features = list(features)\n",
    "\n",
    "for feature in features:\n",
    "    if type(train_X[feature][0]) != np.int64 and gini[feature] < 1.2:\n",
    "        features.remove(feature)\n",
    "        \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('q3b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(train_set, dictionaryX, dictionaryY, means, std_devs, test_data, row_index, filtered_features):\n",
    "    '''\n",
    "        Compute P(Y|feature_values) for test data i.e. a single row from test set\n",
    "    '''\n",
    "    \n",
    "    # Ignore continuous for now\n",
    "    test_matrix = test_data#.drop([' # sentences', ' # words'], axis=1)\n",
    "    \n",
    "    test_X = test_matrix.drop(' is spam', axis=1)\n",
    "    test_Y = test_matrix[' is spam']\n",
    "    \n",
    "    # Calculate \n",
    "    # P(features|label) = multiplier(P(feature_value|label)) and \n",
    "    # P(feature set value) = multiplier(P(feature_value))\n",
    "    x_given_true = 1\n",
    "    x_given_false = 1\n",
    "    \n",
    "    x_probability = 1\n",
    "    for feature in filtered_features:\n",
    "        val = test_X[feature][row_index]\n",
    "        \n",
    "        # For continuous we calculate else we have the value in dictionary of P(feature_value|label)\n",
    "        if type(val) == np.int64:\n",
    "            x_given_true *= computePosterior_contus(data_train=train_set, feature_name=feature, x=val, label=True, means=means, std_devs=std_devs)\n",
    "            x_given_false *= computePosterior_contus(data_train=train_set, feature_name=feature, x=val, label=False, means=means, std_devs=std_devs)\n",
    "        \n",
    "            # For continuous we calculate gaussian function value for P(feature_values), label ='' since full set calculation\n",
    "            x_probability *= gaussian(x=val, means=means, std_devs=std_devs, feature=feature, label='')\n",
    "        else:\n",
    "            key = feature + ', %s' % val + ', spam, True'\n",
    "            x_given_true *= dictionaryX[key]\n",
    "            \n",
    "            key = feature + ', %s' % val + ', spam, False'\n",
    "            x_given_false *= dictionaryX[key]\n",
    "        \n",
    "            # P(feature_values)\n",
    "            key = feature + ', %s' % val\n",
    "            x_probability *= dictionaryX[key]\n",
    "    \n",
    "    false_given_features = x_given_false * dictionaryY['False'] / x_probability\n",
    "    true_given_features = x_given_true * dictionaryY['True'] / x_probability\n",
    "    \n",
    "    return false_given_features, true_given_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in html</th>\n",
       "      <th>has emoji</th>\n",
       "      <th>sent to list</th>\n",
       "      <th>from .com</th>\n",
       "      <th>has my name</th>\n",
       "      <th>has sig</th>\n",
       "      <th># sentences</th>\n",
       "      <th># words</th>\n",
       "      <th>is spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>87</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in html  has emoji  sent to list  from .com  has my name  has sig  \\\n",
       "1    True      False         False       True         True    False   \n",
       "\n",
       "   # sentences  # words  is spam  \n",
       "1            7       87    False  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(test_data.iloc[1])\n",
    "np.transpose(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for test_index in range(0, len(test_data)):\n",
    "    test_frame = pd.DataFrame(test_data.iloc[test_index])\n",
    "    false_prob, true_prob = testing(train_set=train, dictionaryX=dict_X, dictionaryY=dict_Y, means=means, std_devs=std_devs, test_data=np.transpose(test_frame), row_index=test_index, filtered_features=features)\n",
    "    \n",
    "    if false_prob > true_prob:\n",
    "        predictions.append(False)\n",
    "    else:\n",
    "        predictions.append(True)\n",
    "        \n",
    "np.mean(predictions == test_data[' is spam'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for test_index in range(0, len(train)):\n",
    "    test_frame = pd.DataFrame(train.iloc[test_index])\n",
    "    false_prob, true_prob = testing(train_set=train, dictionaryX=dict_X, dictionaryY=dict_Y, means=means, std_devs=std_devs, test_data=np.transpose(test_frame), row_index=test_index, filtered_features=features)\n",
    "    \n",
    "    if false_prob > true_prob:\n",
    "        predictions.append(False)\n",
    "    else:\n",
    "        predictions.append(True)\n",
    "        \n",
    "np.mean(predictions == train[' is spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in html, False, spam, True': 0.2441860465116279,\n",
       " 'in html, False, spam, False': 0.41304347826086957,\n",
       " 'in html, True, spam, True': 0.7558139534883721,\n",
       " 'in html, True, spam, False': 0.5869565217391305,\n",
       " 'in html, False': 0.384,\n",
       " 'in html, True': 0.616,\n",
       " ' has emoji, False, spam, True': 0.8023255813953488,\n",
       " ' has emoji, False, spam, False': 0.8526570048309179,\n",
       " ' has emoji, True, spam, True': 0.19767441860465115,\n",
       " ' has emoji, True, spam, False': 0.1473429951690821,\n",
       " ' has emoji, False': 0.844,\n",
       " ' has emoji, True': 0.156,\n",
       " ' sent to list, True, spam, True': 0.06976744186046512,\n",
       " ' sent to list, True, spam, False': 0.3115942028985507,\n",
       " ' sent to list, False, spam, True': 0.9302325581395349,\n",
       " ' sent to list, False, spam, False': 0.6884057971014492,\n",
       " ' sent to list, True': 0.27,\n",
       " ' sent to list, False': 0.73,\n",
       " ' from .com, True, spam, True': 0.7441860465116279,\n",
       " ' from .com, True, spam, False': 0.2753623188405797,\n",
       " ' from .com, False, spam, True': 0.2558139534883721,\n",
       " ' from .com, False, spam, False': 0.7246376811594203,\n",
       " ' from .com, True': 0.356,\n",
       " ' from .com, False': 0.644,\n",
       " ' has my name, False, spam, True': 0.6511627906976745,\n",
       " ' has my name, False, spam, False': 0.39855072463768115,\n",
       " ' has my name, True, spam, True': 0.3488372093023256,\n",
       " ' has my name, True, spam, False': 0.6014492753623188,\n",
       " ' has my name, False': 0.442,\n",
       " ' has my name, True': 0.558,\n",
       " ' has sig, False, spam, True': 0.3372093023255814,\n",
       " ' has sig, False, spam, False': 0.6763285024154589,\n",
       " ' has sig, True, spam, True': 0.6627906976744186,\n",
       " ' has sig, True, spam, False': 0.32367149758454106,\n",
       " ' has sig, False': 0.618,\n",
       " ' has sig, True': 0.382}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5.,  14.,  56., 135., 247., 252., 181.,  88.,  20.,   2.]),\n",
       " array([-3.6087594 , -2.91405252, -2.21934563, -1.52463874, -0.82993185,\n",
       "        -0.13522496,  0.55948192,  1.25418881,  1.9488957 ,  2.64360259,\n",
       "         3.33830948]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.random.normal(0, 1, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40977574,  0.19636508,  0.20353874, -0.4622873 , -0.98678445,\n",
       "       -1.75366159,  0.33636396,  0.18734605, -0.80418104,  0.58242169,\n",
       "       -0.98403698,  0.70381881, -0.61714542, -0.71394945, -2.10271478,\n",
       "        0.51729044, -0.37586514, -1.91293387,  0.66289186, -1.6206556 ,\n",
       "       -0.10135047,  0.13690744, -0.51215987,  1.0241143 , -0.69134375,\n",
       "       -0.02923648,  0.13410608, -1.49875785,  0.85555071, -0.43952665,\n",
       "       -2.32953989, -0.71543042, -1.05907464,  0.02771831, -0.09454283,\n",
       "       -1.31695547, -1.3824216 , -0.61848801, -0.61595022, -1.04007836,\n",
       "        0.87501878,  1.15715163, -0.01710227,  1.58309311,  0.14109757,\n",
       "        0.95057107,  0.25128356, -0.26884802, -2.37612269, -0.08366743,\n",
       "       -0.99951599, -0.2708276 ,  0.42004774, -0.68927978,  1.67250863,\n",
       "       -0.75258435,  0.22734553,  0.71410213, -0.56388747,  0.2578056 ,\n",
       "        1.48395498,  0.81709274,  0.28083699, -0.82899877,  0.22433986,\n",
       "        0.15746052, -0.87170695, -1.79457296,  0.71648323,  0.11805678,\n",
       "       -1.12840835,  0.71295764,  0.58476031, -0.36512643, -0.90033282,\n",
       "       -0.49701453, -0.10982566, -1.19959447,  0.36130753,  1.77992478,\n",
       "        0.16045504, -1.21368045, -0.92687045, -2.79456453, -1.30846049,\n",
       "       -0.64186978,  0.78217172, -0.09085371, -0.13022222,  1.75500073,\n",
       "       -0.20320532, -0.01880244,  0.40296598, -1.01815722,  0.22099928,\n",
       "        0.68480297,  0.65026148, -0.23889368, -1.0589006 , -0.92889928])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
